{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ff3f901",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'bool' object has no attribute 'sum'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 139\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m    138\u001b[0m test_data_loader \u001b[38;5;241m=\u001b[39m DataLoader(dataset\u001b[38;5;241m=\u001b[39mtest_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 139\u001b[0m test_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 86\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model, data_loader)\u001b[0m\n\u001b[0;32m     84\u001b[0m         predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     85\u001b[0m         total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 86\u001b[0m         correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mpredicted\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     88\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m*\u001b[39m correct \u001b[38;5;241m/\u001b[39m total\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'bool' object has no attribute 'sum'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import struct\n",
    "import random\n",
    "from array import array\n",
    "from os.path  import join\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# MNIST Data Loader Class\n",
    "\n",
    "class MnistDataloader(object):\n",
    "    def __init__(self, training_images_filepath,training_labels_filepath, test_images_filepath, test_labels_filepath):\n",
    "        self.training_images_filepath = training_images_filepath\n",
    "        self.training_labels_filepath = training_labels_filepath\n",
    "        self.test_images_filepath = test_images_filepath\n",
    "        self.test_labels_filepath = test_labels_filepath\n",
    "    \n",
    "    def read_images_labels(self, images_filepath, labels_filepath):        \n",
    "        labels = []\n",
    "        with open(labels_filepath, 'rb') as file:\n",
    "            magic, size = struct.unpack(\">II\", file.read(8))\n",
    "            if magic != 2049:\n",
    "                raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n",
    "            labels = array(\"B\", file.read())        \n",
    "        \n",
    "        with open(images_filepath, 'rb') as file:\n",
    "            magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "            if magic != 2051:\n",
    "                raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
    "            image_data = array(\"B\", file.read())        \n",
    "        images = []\n",
    "        for i in range(size):\n",
    "            images.append([0] * rows * cols)\n",
    "        for i in range(size):\n",
    "            img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n",
    "            img = img.ravel()\n",
    "            images[i][:] = img            \n",
    "        \n",
    "        return images, labels\n",
    "            \n",
    "    def load_data(self):\n",
    "        x_train, y_train = self.read_images_labels(self.training_images_filepath, self.training_labels_filepath)\n",
    "        x_test, y_test = self.read_images_labels(self.test_images_filepath, self.test_labels_filepath)\n",
    "        return (x_train, y_train),(x_test, y_test)  \n",
    "\n",
    "# Define a simple feed-forward NN with five hidden layers    \n",
    "    \n",
    "class SimpleNN(nn.Module):\n",
    "    \n",
    "    # Each hidden layer is of the same size\n",
    "    # ReLU activcation is used\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size, bias=True)\n",
    "        self.layer2 = nn.Linear(hidden_size, hidden_size, bias=True)\n",
    "        self.layer3 = nn.Linear(hidden_size, hidden_size, bias=True)\n",
    "        self.layer4 = nn.Linear(hidden_size, hidden_size, bias=True)\n",
    "        self.layer5 = nn.Linear(hidden_size, hidden_size, bias=True)\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size, bias=True)   \n",
    "\n",
    "    def forward(self, x):   # The forward pass\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.relu(self.layer3(x))\n",
    "        x = self.relu(self.layer4(x))\n",
    "        x = self.relu(self.layer5(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# Model evaluation function    \n",
    "    \n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # No need to track the gradients\n",
    "        for images, labels in data_loader:\n",
    "            outputs = model(images)\n",
    "            predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Model parameters and hyperparameters\n",
    "input_size = 784\n",
    "hidden_size = 16\n",
    "output_size = 10\n",
    "batch_size = 64\n",
    "learn_rate = 0.001\n",
    "number_of_epochs = 100\n",
    "\n",
    "# Where is the MNIST data located?\n",
    "training_images_filepath = 'train-images-idx3-ubyte/train-images-idx3-ubyte'\n",
    "training_labels_filepath = 'train-labels-idx1-ubyte/train-labels-idx1-ubyte'\n",
    "test_images_filepath = 't10k-images-idx3-ubyte/t10k-images-idx3-ubyte'\n",
    "test_labels_filepath = 't10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte'\n",
    "\n",
    "# Create the model, specify our loss function, and our optimizer\n",
    "model = SimpleNN(input_size, hidden_size, output_size)\n",
    "loss_function = nn.CrossEntropyLoss()   # Let us use cross-entropy loss\n",
    "optimizer = optim.SGD(model.parameters(), lr=learn_rate)  # Let us use stochastic gradient descent\n",
    "\n",
    "# Load MINST dataset\n",
    "mnist_dataloader = MnistDataloader(training_images_filepath, training_labels_filepath, test_images_filepath, test_labels_filepath)\n",
    "(x_train, y_train), (x_test, y_test) = mnist_dataloader.load_data()\n",
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)  # Convert to torch tensor\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)  # Convert to torch tensor\n",
    "x_test_tensor = torch.tensor(x_test, dtype=torch.float32)  # Convert to torch tensor\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)  # Convert to torch tensor\n",
    "x_train_tensor /= 255.0   # Normalize, scales the pixel values to the range [0, 1], which is standard practice for image data.\n",
    "x_test_tensor /= 255.0   # Normalize, scales the pixel values to the range [0, 1], which is standard practice for image data.\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "\n",
    "# Training loop\n",
    "\n",
    "data_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for epoch in range(number_of_epochs):\n",
    "    for batch_input, batch_target in data_loader: \n",
    "        # Forward pass\n",
    "        output = model(batch_input)\n",
    "        loss = loss_function(output, batch_target)  # Compute loss \n",
    "\n",
    "        # Backward pass and optimization\n",
    "        model.zero_grad()  # Clear existing gradients\n",
    "        loss.backward()  # Compute gradient of the loss with respect to model parameters\n",
    "        optimizer.step()  # Update parameters\n",
    "\n",
    "# Evaluate the model\n",
    "test_data_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_accuracy = evaluate_model(model, test_data_loader)\n",
    "print(f'Test Accuracy: {test_accuracy}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7109b1d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
